<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <parent>
    <groupId>org.gbif</groupId>
    <artifactId>motherpom</artifactId>
    <version>59</version>
  </parent>

  <groupId>org.gbif.spark</groupId>
  <artifactId>gbif-spark-batch</artifactId>
  <packaging>jar</packaging>
  <version>1.0.0-SNAPSHOT</version>

  <name>GBIF :: gbif-spark-batch</name>
  <description>Batch processes using Spark</description>

  <scm>
    <connection>scm:git:git@github.com:gbif/gbif-spark-batch.git</connection>
    <url>https://github.com/gbif/gbif-spark-batch</url>
    <developerConnection>scm:git:git@github.com:gbif/gbif-spark-batch.git</developerConnection>
    <tag>HEAD</tag>
  </scm>

  <distributionManagement>
    <repository>
      <id>gbif-release</id>
      <url>https://repository.gbif.org/content/repositories/releases</url>
    </repository>
    <snapshotRepository>
      <id>gbif-deploy</id>
      <url>https://repository.gbif.org/content/repositories/snapshots</url>
    </snapshotRepository>
  </distributionManagement>

  <repositories>
    <repository>
      <id>gbif-central</id>
      <url>https://repository.gbif.org/repository/central/</url>
    </repository>
    <repository>
      <id>gbif-release</id>
      <url>https://repository.gbif.org/repository/releases/</url>
    </repository>
    <repository>
      <id>gbif-snapshot</id>
      <url>https://repository.gbif.org/repository/snapshots/</url>
    </repository>
    <repository>
      <id>gbif-thirdparty</id>
      <url>https://repository.gbif.org/repository/thirdparty/</url>
    </repository>
    <repository>
      <id>typesafe-release</id>
      <url>https://repository.gbif.org/repository/typesafe/</url>
    </repository>
  </repositories>

  <properties>
    <!-- Common variables -->
    <jdkLevel>17</jdkLevel>
    <maven.compiler.source>${jdkLevel}</maven.compiler.source>
    <maven.compiler.target>${jdkLevel}</maven.compiler.target>

    <encoding>UTF-8</encoding>
    <project.build.sourceEncoding>${encoding}</project.build.sourceEncoding>
    <project.reporting.outputEncoding>${encoding}</project.reporting.outputEncoding>
    <project.resources.sourceEncoding>${encoding}</project.resources.sourceEncoding>

    <!-- Tools-->
    <lombok.version>1.18.42</lombok.version>

    <!-- Spark -->
    <hadoop.version>3.3.5</hadoop.version>
    <hbase.version>2.6.0-hadoop3</hbase.version>
    <curator.version>5.6.0</curator.version>
    <spark.version>3.5.1</spark.version>
    <iceberg.version>1.6.1</iceberg.version>

    <scala.version>2.12.18</scala.version>

    <!-- These must be compatible with Spark version (see https://stackoverflow.com/a/50114083) -->
    <janino.version>3.1.2</janino.version>
    <commons-compiler.version>3.1.12</commons-compiler.version>
    <resilience4j.version>1.7.0</resilience4j.version>
    <jackson.version>2.19.4</jackson.version>

    <junit4.version>4.13.2</junit4.version>

    <maven-scala-plugin.version>4.8.0</maven-scala-plugin.version>
    <googleJavaFormat.version>1.17.0</googleJavaFormat.version>
    <maven-plugin-plugin.version>3.9.0</maven-plugin-plugin.version>
    <sonar.skip>true</sonar.skip>
  </properties>

  <dependencies>

    <dependency>
      <groupId>org.projectlombok</groupId>
      <artifactId>lombok</artifactId>
      <version>${lombok.version}</version>
      <scope>provided</scope>
    </dependency>

    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_2.12</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_2.12</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.scala-lang</groupId>
      <artifactId>scala-library</artifactId>
      <version>${scala.version}</version>
      <scope>provided</scope>
    </dependency>

    <dependency>
      <groupId>org.apache.iceberg</groupId>
      <artifactId>iceberg-spark-runtime-3.4_2.12</artifactId>
      <version>${iceberg.version}</version>
      <scope>runtime</scope>
    </dependency>

    <dependency>
      <groupId>org.apache.hbase</groupId>
      <artifactId>hbase-client</artifactId>
      <version>${hbase.version}</version>
      <exclusions>
        <!-- Stops the MRAppMaster in Oozie from even starting (when in Oozie) -->
        <exclusion>
          <groupId>org.apache.hadoop</groupId>
          <artifactId>*</artifactId>
        </exclusion>
        <!-- Breaks spark2 -->
        <exclusion>
          <groupId>io.netty</groupId>
          <artifactId>*</artifactId>
        </exclusion>
        <!-- To htrace error -->
        <exclusion>
          <groupId>org.apache.hbase</groupId>
          <artifactId>hbase-hadoop-compat</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.hbase</groupId>
          <artifactId>hbase-hadoop2-compat</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.hbase</groupId>
      <artifactId>hbase-mapreduce</artifactId>
      <version>${hbase.version}</version>
      <exclusions>
        <exclusion>
          <artifactId>hadoop-mapreduce-client-core</artifactId>
          <groupId>org.apache.hadoop</groupId>
        </exclusion>
        <exclusion>
          <artifactId>hadoop-hdfs-client</artifactId>
          <groupId>org.apache.hadoop</groupId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.hbase</groupId>
      <artifactId>hbase-server</artifactId>
      <version>${hbase.version}</version>
      <exclusions>
        <!-- stops the MRAppMaster in Oozie from even starting (when in Oozie) -->
        <exclusion>
          <groupId>org.apache.hadoop</groupId>
          <artifactId>*</artifactId>
        </exclusion>
        <!-- unnecessary bloat -->
        <exclusion>
          <groupId>org.mortbay.jetty</groupId>
          <artifactId>*</artifactId>
        </exclusion>
        <!-- Breaks spark2 -->
        <exclusion>
          <groupId>io.netty</groupId>
          <artifactId>*</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.codehaus.jackson</groupId>
          <artifactId>jackson-core-asl</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.codehaus.jackson</groupId>
          <artifactId>jackson-mapper-asl</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.codehaus.jackson</groupId>
          <artifactId>jackson-jaxrs</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.hadoop</groupId>
      <artifactId>hadoop-client</artifactId>
      <version>${hadoop.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>org.codehaus.jackson</groupId>
          <artifactId>jackson-mapper-asl</artifactId>
        </exclusion>
      </exclusions>
    </dependency>

    <!-- Json -->
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-core</artifactId>
      <version>${jackson.version}</version>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-annotations</artifactId>
      <version>${jackson.version}</version>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>${jackson.version}</version>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.datatype</groupId>
      <artifactId>jackson-datatype-jsr310</artifactId>
      <version>${jackson.version}</version>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.module</groupId>
      <artifactId>jackson-module-scala_2.12</artifactId>
      <version>${jackson.version}</version>
    </dependency>

    <!-- These needed for embedded Spark tests https://stackoverflow.com/a/50114083 -->
    <dependency>
      <groupId>org.codehaus.janino</groupId>
      <artifactId>commons-compiler</artifactId>
      <version>${commons-compiler.version}</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.codehaus.janino</groupId>
      <artifactId>janino</artifactId>
      <version>${janino.version}</version>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>${junit4.version}</version>
    </dependency>
  </dependencies>


  <build>
    <pluginManagement>
      <plugins>
        <plugin>
          <groupId>com.diffplug.spotless</groupId>
          <artifactId>spotless-maven-plugin</artifactId>
          <version>${spotless-maven-plugin.version}</version>
          <configuration combine.self="override">
            <java>
              <googleJavaFormat>
                <version>${googleJavaFormat.version}</version>
                <style>GOOGLE</style>
              </googleJavaFormat>
            </java>
          </configuration>
        </plugin>
        <plugin>
          <groupId>org.apache.maven.plugins</groupId>
          <artifactId>maven-plugin-plugin</artifactId>
          <version>${maven-plugin-plugin.version}</version>
        </plugin>
      </plugins>
    </pluginManagement>
    <plugins>
      <plugin>
        <groupId>com.diffplug.spotless</groupId>
        <artifactId>spotless-maven-plugin</artifactId>
        <executions>
          <execution>
            <!-- Runs in compile phase to fail fast in case of formatting issues.-->
            <id>spotless-check</id>
            <phase>compile</phase>
            <goals>
              <goal>check</goal>
            </goals>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-javadoc-plugin</artifactId>
        <configuration>
          <doclint>none</doclint>
        </configuration>
      </plugin>
      <!-- Shade the project into an uber jar to send to Spark -->
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <configuration>
          <createDependencyReducedPom>false</createDependencyReducedPom>
          <keepDependenciesWithProvidedScope>false</keepDependenciesWithProvidedScope>
          <shadedArtifactAttached>true</shadedArtifactAttached>
          <shadedClassifierName>shaded</shadedClassifierName>
          <!-- Breaks relocations otherwise -->
          <shadeTestJar>false</shadeTestJar>
          <filters>
            <filter>
              <artifact>*:*</artifact>
              <excludes>
                <exclude>META-INF/*.SF</exclude>
                <exclude>META-INF/*.DSA</exclude>
                <exclude>META-INF/*.RSA</exclude>
                <exclude>core-site.xml</exclude>
                <exclude>hbase-site.xml</exclude>
                <exclude>**/config-default.xml</exclude>
              </excludes>
            </filter>
          </filters>
        </configuration>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
            <configuration>
              <transformers>
                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" />
              </transformers>
            </configuration>
          </execution>
        </executions>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-compiler-plugin</artifactId>
        <configuration>
          <source>17</source>
          <target>17</target>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
